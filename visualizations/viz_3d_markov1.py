import math, json
import fire
import re
import logging

import numpy as np
import pandas as pd
import pickle
import networkx as nx
import torch
from torch import Tensor

import io
from PIL import Image
import matplotlib.pyplot as plt

import plotly.express as px
import plotly.graph_objects as go
import dash
from dash.dependencies import Input, Output, State


logger = logging.getLogger(__name__)


class NDDataset(torch.utils.data.Dataset):
    def __init__(
        self, 
        observations: Tensor, 
        latents: Tensor, 
        intervention_labels: Tensor, 
        true_interventions: Tensor, 
        *, 
        graph: nx.Graph = None
    ):
        """Dataset to visualize a THREE-DIMENSIONAL dataset generated by the nd_dataset.py script

        Args:
            observations (Tensor): _description_
            latents (Tensor): _description_
            intervention_labels (Tensor): _description_
            true_interventions (Tensor): _description_
            graph (nx.Graph, optional): _description_. Defaults to None.

        Raises:
            RuntimeError: _description_
        """
        if len(set(map(len, [observations, latents, intervention_labels, true_interventions]))) != 1:
            raise RuntimeError("Not all tensors have the same number of samples")
        
        self.observations = observations
        self.latents = latents
        self.intervention_labels = intervention_labels
        self.true_interventions = true_interventions
        
        self.graph = graph
    
    def __len__(self):
        return len(self.observations)
    
    def __getitem__(self, idx):
        x1, x2 = (
            self.observations[idx, 0, ...], 
            self.observations[idx, 1, ...], 
        )
        z1, z2 = (
            self.latents[idx, 0, ...], 
            self.latents[idx, 1, ...], 
        )
        i_1h_1 = self.intervention_labels[idx, 0, ...]
        i_label_1  = torch.tensor(self.true_interventions[idx, ...])
        return x1, x2, z1, z2, i_1h_1, i_label_1

    def get_idx(self, target_intervention, timestep: int = 0):
        if target_intervention is None:
            return np.arange(len(self))
        a = np.array(target_intervention)
        return np.where((self.intervention_labels[:, timestep, ...].numpy()==a).all(1))[0]

    @classmethod
    def from_files(cls, data_file: str, graph_file: str = None):
        raw_data = torch.load(data_file)
        logger.info(f"Loaded raw data: {raw_data}")

        G = None
        if graph_file is not None:
            G = pickle.load(open(graph_file, "rb"))
        
        return cls(*raw_data, graph=G)
    
    def graph_img(self):
        if self.graph is None:
            logger.info("No graph detected - no DAG will be shown")
            return None

        logger.info("Printing graph structure...")
        fig, ax = plt.subplots()
        nx.draw(self.graph, ax=ax)
        img_buf = io.BytesIO()
        plt.savefig(img_buf, format='png')
        im = Image.open(img_buf)
        return im


def run_app(
    data_file: str,
    graph_file: str = None,
    host: str = "0.0.0.0", 
    port: str = "8899",
    loglevel: str = "INFO",
):
    """

    Make sure you have the additional package requirements:

        pip install fire dash plotly

    Generate the data using 'nd_toy.py':

        TODO
    
    Then, run the app with the following command (point to the created dataset file):

        python viz_3d.py --data_file="../nd_toy_dataset.pt" --port=8899 --loglevel=DEBUG

    Make sure it's a 3d dataset! This app won't work otherwise.
    If you're on the cluster, you'll need to port forward. From your local computer,
    run something like:

        ssh -t -t mila -L 8899:localhost:8899 ssh <MILA_USERNAME>@cn-g003 -L 8899:localhost:8899

    where you might replace 'cn-g003' with the appropriate worker node you are running 
    on, and '8899' with the port you've specified previously. You can then view the
    app in your local browser at http://localhost:8899/

    Args:
        data_file (str): Path to pt file saved by nd_toy.py.
        graph_file (str, optional): Not implemented yet. Defaults to None.
        host (str, optional): Host url for the app.
        port (str, optional): What port to serve the app on.
        loglevel (str, optional): One of DEBUG, INFO, WARN, ERROR. Defaults to "INFO".
    """
    logging.basicConfig(level=logging.getLevelName(loglevel))

    # Load the NDDataset
    dataset = NDDataset.from_files(data_file, graph_file)

    # Create a 3D scatter plot
    fig = go.Figure(
        data=[
            go.Scatter3d(
                x=[1.0],
                y=[0.0],
                z=[0.0],
                mode='markers',
                marker=dict(
                    symbol='circle',
                    size=2,
                    color='darkgreen',
                    opacity=0.8,
                ),
                name="z1",
            ),
            go.Scatter3d(
                x=[0.0],
                y=[1.0],
                z=[0.0],
                mode='markers',
                marker=dict(
                    symbol='square',
                    size=2,
                    color='blue',
                    opacity=1,
                ),
                name="z2",
            ),
        ],
        layout = go.Layout(
            title="Latent Variables Z",
            width=1200,
            height=1200
        )
    )

    # Build App
    app = dash.Dash(__name__)
    app.layout = dash.html.Div([
        dash.dcc.Input(id='input1', value="000", type='text', placeholder='Intervention (e.g 110)'),
        dash.html.Button('Update data', id='update-data', n_clicks=0),
        dash.html.Button('Reset lines', id='reset', n_clicks=0),
        dash.html.Button('Dump cached', id='dump-cache', n_clicks=0),

        dash.html.Div(id="where",),

        dash.dcc.Graph(id="3dgraph", figure=fig),

        dash.html.Div(id="meh"),

        dash.html.Img(src=dataset.graph_img()),

        # dcc.Store stores the intermediate value

        dash.dcc.Store(id='garbage'),
        dash.dcc.Store(id='lines'),
        dash.dcc.Store(id='selected-idx'),
        dash.dcc.Store(id='z1'),
        dash.dcc.Store(id='z2'),
    ])


    @app.callback(
        Output("3dgraph", "figure"),
        Output("selected-idx", "data"),
        Output("z1", "data"),
        Output("z2", "data"),
        Input('update-data', 'n_clicks'),
        Input('lines', 'data'),
        State("input1", "value"),
    )
    def update_graph(clicks, lines, input1):
        def _parse_inputs(input):
            if input == '' or input is None:
                return None
            m = re.match("\[?(\d)\,?(\d)\,?(\d)\]?", input)
            digits = np.array([int(i) for i in m.groups()])
            return digits

        # Parse the inputs
        logger.debug({"input1": input1})
        interv_1 = _parse_inputs(input1)
        logger.debug({"input1": interv_1}) 
        
        # Filter the points; if any intervention is None, it would select all pts
        # Then, get intersection of the two lists to do the final selection 
        idx_1 = dataset.get_idx(interv_1, 0)  
        selected = idx_1
        logger.debug(idx_1)
        logger.info(f"Selected indices:\n{selected}")

        x1, x2, z1, z2, i_1h_1, i_label_1 = dataset[selected]

        logger.debug(f"Interventions timestep 1: {i_1h_1[0]} - {torch.all(i_1h_1==i_1h_1[0])}")
        logger.debug(f"Sizes: z1 - {z1.shape}\tz2 - {z2.shape}")

        # Remove any extra traces (lines)
        fig.data = fig.data[:3]

        # Update the data of the 3D graph
        all_z = [z1, z2]

        for f, z in zip(fig.data[:3], all_z):
            f.x = z[:, 0]
            f.y = z[:, 1]
            f.z = z[:, 2]

        fig.add_traces(lines)
        return fig, selected, z1, z2
        

    @app.callback(
        Output('garbage', 'data'),
        Input('dump-cache', 'n_clicks'),
        State("selected-idx", "data"),
        State("z1", "data"),
        State("z2", "data"),
        State("lines", "data"),
    )
    def dump_cached(click, selected, z1, z2, lines):
        """Debug dump of cached data"""
        logging.debug("Dumping cached data:")
        if selected is not None:
            logging.debug(f"Selected:\n{selected}\n")
            logging.debug(f"z1:\n{torch.tensor(z1).round(decimals=1)}\n")
            logging.debug(f"z2:\n{torch.tensor(z2).round(decimals=1)}\n")
            logging.debug(f"lines:\n{lines}")
        return np.array([])
    

    @app.callback(
        Output("where", "children"),
        Output("lines", "data"),
        Input("3dgraph", "clickData"),
        Input("reset", "n_clicks"),
        State("lines", "data"),
        State("selected-idx", "data"),
        State("z1", "data"),
        State("z2", "data"),
    )
    def click(clickData, reset_clicks, lines, selected, z1, z2):
        """Add a line for the points clicked"""

        if dash.ctx.triggered_id == "reset":
            return "Resetting graph...", []

        if not clickData:
            raise dash.exceptions.PreventUpdate

        # Get the index of the clicked point
        logger.debug(clickData)
        idx = clickData["points"][0]["pointNumber"]
        logger.debug(f"Clicked index: {idx}")

        _z1, _z2 = z1[idx], z2[idx]

        # Add line
        line = [
            go.Scatter3d(
                x=[_z1[0], _z2[0]],
                y=[_z1[1], _z2[1]],
                z=[_z1[2], _z2[2]],
                mode='lines',
                line=dict(
                    color='red',
                    width=2,
                ),
                name=idx
            ),
        ]
        dump = json.dumps({k: clickData["points"][0][k] for k in ["x", "y", "z"]})

        if lines is None:
            lines = []
        lines.extend(line)

        return dump, lines

    app.run_server(debug=True, host=host, port=port, dev_tools_hot_reload=True)


if __name__ == "__main__":
    fire.Fire(run_app)